from lxml.html.clean import Cleaner
from scrapu_class import DSSpider
from scrapy.http import TextResponse

def test_parse():
    """Test function for DSSpider.parse()"""
    # Create test response
    test_html = """
    <html>
        <head>
            <title>Test Page Title</title>  <!-- 添加标题 -->
        </head>
        <body>
            <button formaction="javascript:alert('XSS')">Click me</button>
            <form id="test"></form>
        </body>
    </html>
    """
    response = TextResponse(
        url='https://quotes.toscrape.com/page/1/',
        body=test_html,
        encoding='utf-8'
    )

    # Test parsing
    spider = DSSpider()
    result = spider.parse(response)

    # Assertions

if __name__ == '__main__':
    test_parse()

    vulnerable_cleaner = Cleaner(
        safe_attrs_only=False,
        forms=False,
        javascript=False,
        style=False
    )

    malicious_html = '''
    <button formaction="javascript:alert('XSS')">Click me</button>
    <form id="test"></form>
    '''
    # 清理后的HTML仍包含恶意属性
    cleaned = vulnerable_cleaner.clean_html(malicious_html)
    print(cleaned)
