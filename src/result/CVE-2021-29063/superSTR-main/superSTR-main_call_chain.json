[
    [
        {
            "function_name": "p_value_test",
            "file_path": "/PycharmProjects/PyVul/src/contet/dataset/test_data/CVE-2021-29063/superSTR-main/Python/screen.py",
            "line_number": 55,
            "source_code": "def p_value_test(n_gt, n_trials, n_grp1, n_grp2):\n    m_t = binomial(n_grp1 + n_grp2, n_grp1)\n    p_val = mpmathify((n_gt + 1) / (n_trials + 1)) - quadgl(\n        lambda : cdf(, n_gt, n_trials), [0, (0.5 / m_t)])\n    return p_val\n",
            "parameters": [],
            "focused_calls": [
                "mpmathify"
            ],
            "etend_calls": [
                "def cdf(p, , n):\n    cumsum = mpmathify(0)\n    for i in range(0,  + 1):\n        cumsum = cumsum + binomial(n, i) * power(p, i) * power((1 - p),\n                                                               (n - i))\n    return cumsum"
            ],
            "conditions_for_focused_calls": {},
            "parameter_conditions": "",
            "is_vulnerability_reachable": false,
            "unique_id": "/PycharmProjects/PyVul/src/contet/dataset/test_data/CVE-2021-29063/superSTR-main/Python/screen.py:p_value_test:55"
        },
        {
            "function_name": "score_df",
            "file_path": "/PycharmProjects/PyVul/src/contet/dataset/test_data/CVE-2021-29063/superSTR-main/Python/screen.py",
            "line_number": 62,
            "source_code": "def score_df(motif, f_path, manifest_df, control_label, n_trials,\n             swap_labs=False, min_threshold=3):\n    current_data = pd.read_csv(f_path)\n    current_data = current_data.fillna(0.0)\n    current_data = infill(current_data, manifest_df)\n    current_data[\"info_score\"] = current_data.apply(information_score, ais=1)\n    if swap_labs:\n        current_data.set_inde(\"sample\", inplace=True, drop=False)\n        current_data.update(manifest_df)\n    targ_list = current_data.grp.unique()\n    results = []\n    for targ in targ_list:\n        if targ == control_label:\n            continue\n        if len(current_data[current_data[\"grp\"] == targ]) <= min_threshold:\n            continue\n        cases = current_data.loc[current_data[\"grp\"] == targ][\"info_score\"]\n        controls = current_data.loc[current_data[\"grp\"] != targ][\"info_score\"]\n        if len(cases) == 0 or len(controls) == 0 or sum(cases) == 0.0 or sum(\n                controls) == 0.0:\n            continue\n        mann_whitney_stat, mann_whitney_p = mannwhitneyu(cases, controls,\n                                                         alternative=\"greater\")\n        n_cases = len(cases)\n        n_controls = len(current_data) - n_cases\n        mwu_perm_list = list()\n        for i in range(0, n_trials):\n            current_data = current_data.sample(frac=1.0)\n            cases = current_data.iloc[0:n_cases][\"info_score\"]\n            controls = current_data.iloc[n_cases:][\"info_score\"]\n            mwu_result = mannwhitneyu(cases, controls, alternative=\"greater\")\n            mwu_perm_list.append(mwu_result[0])\n        mwu_perm_list = np.asarray(mwu_perm_list)\n        n_gt = (mwu_perm_list > mann_whitney_stat).sum()\n        # P-value calculated per Smyth and Phipson\n        perm_p = p_value_test(n_gt, n_trials, n_cases, n_controls)\n        result_tuple = (\n            targ, len(cases), motif, mann_whitney_stat, mann_whitney_p, perm_p)\n        results.append(result_tuple)\n    return results\n",
            "parameters": [],
            "focused_calls": [
                "p_value_test"
            ],
            "etend_calls": [
                "def infill(if_df, manifest_df):\n    all_snames = set(manifest_df.inde)\n    obs_snames = set(if_df[\"sample\"].unique())\n    to_add = all_snames-obs_snames\n    rlen = if_df.rlen.ma()\n    add_dict = {}\n    for id in range(1, rlen+1):\n        add_dict[str(id)] = 0.0\n    add_dict[\"motif\"] = if_df.iloc[0].motif\n    add_dict[\"mlen\"] = if_df.iloc[0].mlen\n    add_dict[\"rlen\"] = rlen\n    for add_samp in to_add:\n        add_dict[\"sample\"] = add_samp\n        add_dict[\"grp\"] = manifest_df.loc[add_samp].grp\n        if_df = if_df.append(add_dict, ignore_inde=True)\n    return if_df",
                "def p_value_test(n_gt, n_trials, n_grp1, n_grp2):\n    m_t = binomial(n_grp1 + n_grp2, n_grp1)\n    p_val = mpmathify((n_gt + 1) / (n_trials + 1)) - quadgl(\n        lambda : cdf(, n_gt, n_trials), [0, (0.5 / m_t)])\n    return p_val"
            ],
            "conditions_for_focused_calls": {},
            "parameter_conditions": "",
            "is_vulnerability_reachable": false,
            "unique_id": "/PycharmProjects/PyVul/src/contet/dataset/test_data/CVE-2021-29063/superSTR-main/Python/screen.py:score_df:62"
        },
        {
            "function_name": "process_file",
            "file_path": "/PycharmProjects/PyVul/src/contet/dataset/test_data/CVE-2021-29063/superSTR-main/Python/screen.py",
            "line_number": 104,
            "source_code": "def process_file(fname, manifest_path, control_label, use_status, n_perm, min_threshold):\n    manifest_df = pd.read_csv(manifest_path, sep=\"\\t\",\n                              names=[\"sample\", \"status\", \"path\", \"grp\"])\n    manifest_df.set_inde(\"sample\", inplace=True)\n    motif = basename(fname).replace(\".csv\", \"\")\n    motif_results = score_df(motif, fname, manifest_df, control_label, n_perm,\n                             swap_labs=use_status, min_threshold=min_threshold)\n    return motif_results\n",
            "parameters": [],
            "focused_calls": [
                "score_df"
            ],
            "etend_calls": [
                "def score_df(motif, f_path, manifest_df, control_label, n_trials,\n             swap_labs=False, min_threshold=3):\n    current_data = pd.read_csv(f_path)\n    current_data = current_data.fillna(0.0)\n    current_data = infill(current_data, manifest_df)\n    current_data[\"info_score\"] = current_data.apply(information_score, ais=1)\n    if swap_labs:\n        current_data.set_inde(\"sample\", inplace=True, drop=False)\n        current_data.update(manifest_df)\n    targ_list = current_data.grp.unique()\n    results = []\n    for targ in targ_list:\n        if targ == control_label:\n            continue\n        if len(current_data[current_data[\"grp\"] == targ]) <= min_threshold:\n            continue\n        cases = current_data.loc[current_data[\"grp\"] == targ][\"info_score\"]\n        controls = current_data.loc[current_data[\"grp\"] != targ][\"info_score\"]\n        if len(cases) == 0 or len(controls) == 0 or sum(cases) == 0.0 or sum(\n                controls) == 0.0:\n            continue\n        mann_whitney_stat, mann_whitney_p = mannwhitneyu(cases, controls,\n                                                         alternative=\"greater\")\n        n_cases = len(cases)\n        n_controls = len(current_data) - n_cases\n        mwu_perm_list = list()\n        for i in range(0, n_trials):\n            current_data = current_data.sample(frac=1.0)\n            cases = current_data.iloc[0:n_cases][\"info_score\"]\n            controls = current_data.iloc[n_cases:][\"info_score\"]\n            mwu_result = mannwhitneyu(cases, controls, alternative=\"greater\")\n            mwu_perm_list.append(mwu_result[0])\n        mwu_perm_list = np.asarray(mwu_perm_list)\n        n_gt = (mwu_perm_list > mann_whitney_stat).sum()\n        # P-value calculated per Smyth and Phipson\n        perm_p = p_value_test(n_gt, n_trials, n_cases, n_controls)\n        result_tuple = (\n            targ, len(cases), motif, mann_whitney_stat, mann_whitney_p, perm_p)\n        results.append(result_tuple)\n    return results"
            ],
            "conditions_for_focused_calls": {},
            "parameter_conditions": "",
            "is_vulnerability_reachable": false,
            "unique_id": "/PycharmProjects/PyVul/src/contet/dataset/test_data/CVE-2021-29063/superSTR-main/Python/screen.py:process_file:104"
        }
    ]
]
